{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"data/\"\n",
    "logs = \"lightning_logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "num_workers = 4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    return 100*((y==y_hat).sum().item())/y.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "data_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 169861120/170498071 [00:54<00:00, 6062847.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data/\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [01:10, 6062847.66it/s]                               "
     ]
    }
   ],
   "source": [
    "# download the data\n",
    "train = torchvision.datasets.cifar.CIFAR10(root=root, train=True, transform=data_transform, download=True)\n",
    "val = torchvision.datasets.cifar.CIFAR10(root=root, train=False, transform=data_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure PyTorch code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=3, n_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1) # 32x32x3 -> 16x16x16\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1) # 16x16x16 -> 8x8x32\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1) # 4x4x64\n",
    "        self.linear = torch.nn.Linear(in_features=4*4*64, out_features=124)\n",
    "        self.output = torch.nn.Linear(in_features=124, out_features=n_classes)\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = torch.nn.Dropout(p=0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(torch.nn.functional.relu(self.conv1(x)))\n",
    "        x = self.maxpool(torch.nn.functional.relu(self.conv2(x)))\n",
    "        x = self.maxpool(torch.nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4) # 4x4x64 -> 4*4*64\n",
    "        x = torch.nn.functional.relu(self.linear(x))\n",
    "        out = self.output(x)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer, Loss and Tensorboard writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "criterian = torch.nn.CrossEntropyLoss()\n",
    "writer = torch.utils.tensorboard.SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Good, the Bad and the Ugly training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 10.5 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   4%|▍         | 15/391 [00:00<01:58,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | steps  0 | loss 2.3017399311065674 | accuracy 10.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  59%|█████▉    | 231/391 [00:01<00:01, 88.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | steps  200 | loss 1.4653867483139038 | accuracy 42.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s]76s/it]4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train_loss 1.7090767256134307 | train_acc 37.739769820971865 | val_loss 1.4385334853930851 | val_acc 48.21651214833759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 1/391 [00:00<00:44,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | steps  400 | loss 1.4200018644332886 | accuracy 42.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  58%|█████▊    | 228/391 [00:02<00:01, 108.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | steps  600 | loss 1.2921485900878906 | accuracy 52.34375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 391/391 [00:04<00:00, 78.54it/s] it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train_loss 1.3476582924118432 | train_acc 51.757912404092075 | val_loss 1.2525760712830916 | val_acc 55.40521099744245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch:  13%|█▎        | 49/391 [00:00<00:16, 21.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | steps  800 | loss 1.2550618648529053 | accuracy 56.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  59%|█████▉    | 231/391 [00:01<00:01, 135.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | steps  1000 | loss 1.1927508115768433 | accuracy 59.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 391/391 [00:05<00:00, 78.02it/s] \n",
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s]93s/it]0.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | train_loss 1.206453739987005 | train_acc 57.12875639386189 | val_loss 1.1215903101979618 | val_acc 60.169037723785166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  13%|█▎        | 51/391 [00:00<00:15, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 | steps  1200 | loss 1.040155291557312 | accuracy 63.28125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  63%|██████▎   | 247/391 [00:01<00:00, 146.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 | steps  1400 | loss 1.179186463356018 | accuracy 62.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 391/391 [00:05<00:00, 66.15it/s] it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | train_loss 1.0982377253225089 | train_acc 61.1644820971867 | val_loss 1.0418566241288734 | val_acc 62.8360773657289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch:  15%|█▌        | 60/391 [00:00<00:13, 24.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 | steps  1600 | loss 0.9231236577033997 | accuracy 73.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  65%|██████▍   | 254/391 [00:01<00:00, 145.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 | steps  1800 | loss 0.9883641004562378 | accuracy 60.15625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s]27s/it]0.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | train_loss 1.0146730539134092 | train_acc 64.08407928388746 | val_loss 0.9535489679907289 | val_acc 66.167679028133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  21%|██        | 83/391 [00:00<00:07, 39.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 | steps  2000 | loss 0.8560163378715515 | accuracy 70.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  68%|██████▊   | 266/391 [00:01<00:00, 137.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 | steps  2200 | loss 0.9519298076629639 | accuracy 69.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 391/391 [00:05<00:00, 70.67it/s] \n",
      "Batch: 100%|██████████| 391/391 [00:05<00:00, 70.40it/s] t/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | train_loss 0.9460416146556435 | train_acc 66.80866368286445 | val_loss 0.8764826836793319 | val_acc 69.55722506393862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch:  18%|█▊        | 70/391 [00:00<00:09, 34.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 | steps  2400 | loss 1.1046710014343262 | accuracy 60.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  72%|███████▏  | 280/391 [00:02<00:00, 137.43it/s]it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 | steps  2600 | loss 0.8642760515213013 | accuracy 73.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s]59s/it]6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | train_loss 0.8969542775922419 | train_acc 68.5465952685422 | val_loss 0.874965284791444 | val_acc 69.33343989769821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  20%|█▉        | 78/391 [00:00<00:07, 41.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 | steps  2800 | loss 0.7764450907707214 | accuracy 71.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  73%|███████▎  | 287/391 [00:02<00:00, 108.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 | steps  3000 | loss 0.7623276114463806 | accuracy 73.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 391/391 [00:05<00:00, 67.35it/s] \n",
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s]54s/it]3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | train_loss 0.840111425465635 | train_acc 70.59662723785166 | val_loss 0.7811438735488736 | val_acc 72.71938938618926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  25%|██▌       | 99/391 [00:00<00:05, 48.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 | steps  3200 | loss 0.960803210735321 | accuracy 64.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  77%|███████▋  | 301/391 [00:02<00:00, 144.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 | steps  3400 | loss 0.7504127025604248 | accuracy 74.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 391/391 [00:05<00:00, 71.39it/s]8it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | train_loss 0.8008349454006576 | train_acc 71.91256393861893 | val_loss 0.7462484208519197 | val_acc 73.87547953964194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch:  27%|██▋       | 104/391 [00:00<00:05, 55.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 | steps  3600 | loss 0.7073818445205688 | accuracy 75.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  79%|███████▉  | 308/391 [00:01<00:00, 161.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 | steps  3800 | loss 0.7518342733383179 | accuracy 72.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 391/391 [00:04<00:00, 87.44it/s] \n",
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s].45s/it].85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | train_loss 0.7605257762210144 | train_acc 73.41272378516624 | val_loss 0.7185067005474549 | val_acc 74.89490089514067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  28%|██▊       | 110/391 [00:00<00:04, 59.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 | steps  4000 | loss 0.7514327764511108 | accuracy 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  81%|████████  | 317/391 [00:02<00:00, 148.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 | steps  4200 | loss 0.6244916915893555 | accuracy 82.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 391/391 [00:06<00:00, 64.38it/s] it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss 0.7227150082130871 | train_acc 74.83296035805627 | val_loss 0.6625540265646737 | val_acc 77.10158248081841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch:  33%|███▎      | 130/391 [00:01<00:04, 60.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 | steps  4400 | loss 0.7792284488677979 | accuracy 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  82%|████████▏ | 322/391 [00:03<00:00, 123.89it/s]it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 | steps  4600 | loss 0.646674394607544 | accuracy 75.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s].63s/it].03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train_loss 0.6947827723325061 | train_acc 75.73489450127877 | val_loss 0.6380498934432369 | val_acc 77.79132033248082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  33%|███▎      | 128/391 [00:01<00:04, 58.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 | steps  4800 | loss 0.5179007053375244 | accuracy 81.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  87%|████████▋ | 339/391 [00:03<00:00, 103.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 | steps  5000 | loss 0.6501489877700806 | accuracy 80.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 391/391 [00:06<00:00, 62.19it/s] \n",
      "Batch: 100%|██████████| 391/391 [00:06<00:00, 60.96it/s] it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train_loss 0.6612271098682033 | train_acc 76.8274456521739 | val_loss 0.6099795777626964 | val_acc 78.77157928388746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch:  38%|███▊      | 148/391 [00:01<00:02, 87.36it/s]4it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 | steps  5200 | loss 0.7454145550727844 | accuracy 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  87%|████████▋ | 341/391 [00:02<00:00, 151.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 | steps  5400 | loss 0.5883215665817261 | accuracy 84.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s].79s/it].21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train_loss 0.6364156612959664 | train_acc 77.5675351662404 | val_loss 0.574451186925249 | val_acc 79.97442455242967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  38%|███▊      | 150/391 [00:01<00:02, 88.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 | steps  5600 | loss 0.7146062850952148 | accuracy 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  91%|█████████ | 354/391 [00:03<00:00, 135.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 | steps  5800 | loss 0.6260130405426025 | accuracy 80.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 391/391 [00:07<00:00, 55.68it/s] \n",
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s].23s/it].19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train_loss 0.597675963207279 | train_acc 79.144820971867 | val_loss 0.6152856245522609 | val_acc 78.20092710997443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  43%|████▎     | 169/391 [00:01<00:02, 106.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 | steps  6000 | loss 0.6517689228057861 | accuracy 75.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  88%|████████▊ | 345/391 [00:02<00:00, 69.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 | steps  6200 | loss 0.47682151198387146 | accuracy 84.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 391/391 [00:05<00:00, 72.24it/s]8it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train_loss 0.5799398330014075 | train_acc 79.74504475703324 | val_loss 0.5629044825311207 | val_acc 80.33288043478261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch:  43%|████▎     | 170/391 [00:01<00:02, 104.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 | steps  6400 | loss 0.5441251397132874 | accuracy 82.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  94%|█████████▍| 367/391 [00:02<00:00, 167.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 | steps  6600 | loss 0.46984192728996277 | accuracy 82.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 391/391 [00:04<00:00, 83.15it/s] \n",
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s].67s/it].44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train_loss 0.5553489934148081 | train_acc 80.57145140664962 | val_loss 0.489836784503649 | val_acc 83.25567455242967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  48%|████▊     | 189/391 [00:01<00:01, 123.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 | steps  6800 | loss 0.48806992173194885 | accuracy 86.71875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  97%|█████████▋| 379/391 [00:02<00:00, 171.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 | steps  7000 | loss 0.530581533908844 | accuracy 80.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 391/391 [00:05<00:00, 68.03it/s] it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train_loss 0.5249741957010821 | train_acc 81.56809462915601 | val_loss 0.45499724477453307 | val_acc 84.53804347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch:  48%|████▊     | 186/391 [00:01<00:01, 120.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 | steps  7200 | loss 0.48228850960731506 | accuracy 82.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/391 [00:00<?, ?it/s]4it/s]it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 | steps  7400 | loss 0.42572319507598877 | accuracy 85.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/391 [00:00<?, ?it/s].64s/it].68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train_loss 0.5052313443339999 | train_acc 82.40768861892583 | val_loss 0.47312118642775297 | val_acc 83.42990728900256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  48%|████▊     | 187/391 [00:01<00:01, 116.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 | steps  7600 | loss 0.30616268515586853 | accuracy 88.28125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 391/391 [00:05<00:00, 70.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 | steps  7800 | loss 0.5120217800140381 | accuracy 80.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100%|██████████| 20/20 [01:51<00:00,  5.42s/it].62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train_loss 0.48032914387905384 | train_acc 83.12380115089515 | val_loss 0.43226598389923115 | val_acc 85.15305306905371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 391/391 [00:13<00:00, 208.62it/s]"
     ]
    }
   ],
   "source": [
    "%time\n",
    "steps = 0\n",
    "\n",
    "epoch_progress = tqdm.tqdm(total=epochs, desc=\"Epoch\", position=0)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_loss = []\n",
    "    epoch_train_acc = []\n",
    "    epoch_val_loss = []\n",
    "    epoch_val_acc = []\n",
    "    \n",
    "    batch_progress = tqdm.tqdm(total=len(train_loader), desc=\"Batch\", position=0)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # calculate the loss and batch accuracy\n",
    "        loss = criterian(outputs, labels)\n",
    "        acc = accuracy(labels, torch.argmax(outputs, 1))\n",
    "        \n",
    "        \n",
    "        # backpropagate the loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if steps%200==0:\n",
    "            print(f'epoch {epoch} | steps  {steps} | loss {loss.item()} | accuracy {acc}')\n",
    "        \n",
    "        epoch_train_loss.append(loss.item())\n",
    "        epoch_train_acc.append(acc)\n",
    "        \n",
    "        writer.add_scalar(\"step_wise_loss\", loss.item(), steps)\n",
    "        writer.add_scalar(\"step_wise_acc\", acc, steps)\n",
    "        \n",
    "        batch_progress.update(1)\n",
    "        steps += 1\n",
    "        \n",
    "        \n",
    "    \n",
    "    val_progress = tqdm.tqdm(total=len(val_loader), desc=\"Validation\", position=0)\n",
    "    for i, (images, labels) in enumerate(val_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            # forward pass with no grads\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # loss and acc calcualtion\n",
    "            loss = criterian(outputs, labels)\n",
    "            acc = accuracy(labels, torch.argmax(outputs, 1))\n",
    "            \n",
    "            epoch_val_loss.append(loss.item())\n",
    "            epoch_val_acc.append(acc)\n",
    "            \n",
    "            val_progress.update(1)\n",
    "    \n",
    "    # calculate the epochs wise train, val loss and acc\n",
    "    t_loss = sum(epoch_train_loss)/len(epoch_train_loss)\n",
    "    t_acc = sum(epoch_train_acc)/len(epoch_train_acc)\n",
    "    v_loss = sum(epoch_val_loss)/len(epoch_val_loss)\n",
    "    v_acc = sum(epoch_val_acc)/len(epoch_val_acc)\n",
    "    \n",
    "    # add to tensorboard\n",
    "    writer.add_scalar(\"train_loss\", t_loss, epoch)\n",
    "    writer.add_scalar(\"train_acc\", t_acc, epoch)\n",
    "    writer.add_scalar(\"val_loss\", v_loss, epoch)\n",
    "    writer.add_scalar(\"val_acc\", v_acc, epoch)\n",
    "    \n",
    "    print(f\"Epoch {epoch} | train_loss {t_loss} | train_acc {t_acc} | val_loss {v_loss} | val_acc {v_acc}\")\n",
    "    \n",
    "    epoch_progress.update(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macab/miniconda3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (linear): Linear(in_features=1024, out_features=124, bias=True)\n",
       "  (output): Linear(in_features=124, out_features=10, bias=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch-Lightning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"lightning_logs/version_0/checkpoints/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, in_channels=3, n_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1) # 32x32x3 -> 16x16x16\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1) # 16x16x16 -> 8x8x32\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1) # 8x8x32 -> 4x4x64\n",
    "        self.linear = torch.nn.Linear(in_features=4*4*64, out_features=128)\n",
    "        self.output = torch.nn.Linear(in_features=128, out_features=n_classes)\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = torch.nn.Dropout(p=0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(torch.nn.functional.relu(self.maxpool(self.conv1(x))))\n",
    "        x = self.dropout(torch.nn.functional.relu(self.maxpool(self.conv2(x))))\n",
    "        x = self.dropout(torch.nn.functional.relu(self.maxpool(self.conv3(x))))\n",
    "        x = x.view(-1, 4*4*64)\n",
    "        x = self.dropout(self.linear(x))\n",
    "        out = self.output(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=lr)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = torchvision.datasets.cifar.CIFAR10(root=root, train=True, transform=data_transform, download=True)\n",
    "        loader = torch.utils.data.DataLoader(dataset=dataset,  batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        return loader\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        \n",
    "        # loss and accuracy\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        acc = accuracy(labels, torch.argmax(outputs, 1))\n",
    "        log = {\"loss\":loss, \"acc\":torch.tensor(acc)}\n",
    "        return {\"loss\":loss, \"acc\":torch.tensor(acc), \"log\":log}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"acc\"] for x in outputs]).mean()\n",
    "        log = {\"epoch_loss\":avg_loss, \"epoch_acc\":avg_acc}\n",
    "        return {\"epoch_loss\":avg_loss, \"epoch_acc\":avg_acc, \"log\":log}\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        dataset = torchvision.datasets.cifar.CIFAR10(root=root, train=False, transform=data_transform, download=True)\n",
    "        loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        return loader\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        \n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        acc = accuracy(labels, torch.argmax(outputs, 1))\n",
    "        \n",
    "        log = {\"val_loss\":loss, \"val_acc\":torch.tensor(acc)}\n",
    "        return {\"val_loss\":loss, \"val_acc\":torch.tensor(acc), \"log\":log}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"val_acc\"] for x in outputs]).mean()\n",
    "        \n",
    "        log = {\"val_loss\":avg_loss, \"val_acc\":avg_acc}\n",
    "        return {\"val_loss\":avg_loss, \"val_acc\":avg_acc, \"log\":log}\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        dataset = torchvision.datasets.cifar.CIFAR10(root=root, train=False, transform=data_transform, download=True)\n",
    "        loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        return loader\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        \n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        acc = accuracy(labels, torch.argmax(outputs, 1))\n",
    "        \n",
    "        log = {\"test_loss\":loss, \"test_acc\":torch.tensor(acc)}\n",
    "        return {\"test_loss\":loss, \"test_acc\":torch.tensor(acc), \"log\":log}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\n",
    "        \n",
    "        log = {\"test_loss\":avg_loss, \"test_acc\":avg_acc}\n",
    "        return {\"test_loss\":avg_loss, \"test_acc\":avg_acc, \"log\":log}\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macab/miniconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: Checkpoint directory lightning_logs/ exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=3)\n",
    "model_checkpoint = ModelCheckpoint(filepath=\"lightning_logs/\", monitor=\"val_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create model and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "# create pl trainer object \n",
    "trainer = pl.Trainer(\n",
    "    gpus=[0],\n",
    "    weights_summary=None,\n",
    "    show_progress_bar=True,\n",
    "    max_epochs=10,\n",
    "#     callbacks=[early_stopping, model_checkpoint]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified      \n",
      "Files already downloaded and verified\n",
      "Epoch 1:  83%|████████▎ | 782/939 [00:04<00:00, 174.87it/s, loss=1.426, v_num=0]\n",
      "Epoch 1:  84%|████████▎ | 785/939 [00:04<00:00, 172.66it/s, loss=1.426, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 828/939 [00:04<00:00, 178.16it/s, loss=1.426, v_num=0]\n",
      "Epoch 1:  94%|█████████▎| 878/939 [00:04<00:00, 184.92it/s, loss=1.426, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 928/939 [00:04<00:00, 191.00it/s, loss=1.426, v_num=0]\n",
      "Epoch 1: 100%|██████████| 939/939 [00:04<00:00, 191.35it/s, loss=1.426, v_num=0]\n",
      "Epoch 2:   0%|          | 0/939 [00:00<?, ?it/s, loss=1.426, v_num=0]           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macab/miniconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: Did not find hyperparameters at model hparams. Saving checkpoint without hyperparameters.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  83%|████████▎ | 782/939 [00:04<00:00, 169.64it/s, loss=1.282, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 800/939 [00:04<00:00, 169.49it/s, loss=1.282, v_num=0]\n",
      "Epoch 2:  91%|█████████ | 851/939 [00:04<00:00, 176.46it/s, loss=1.282, v_num=0]\n",
      "Epoch 2:  96%|█████████▌| 902/939 [00:04<00:00, 182.59it/s, loss=1.282, v_num=0]\n",
      "Epoch 2: 100%|██████████| 939/939 [00:05<00:00, 185.90it/s, loss=1.282, v_num=0]\n",
      "Epoch 3:  83%|████████▎ | 782/939 [00:04<00:00, 166.02it/s, loss=1.255, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 816/939 [00:04<00:00, 167.26it/s, loss=1.255, v_num=0]\n",
      "Epoch 3:  92%|█████████▏| 867/939 [00:05<00:00, 173.35it/s, loss=1.255, v_num=0]\n",
      "Validating:  57%|█████▋    | 89/157 [00:00<00:00, 160.26it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 939/939 [00:05<00:00, 180.31it/s, loss=1.255, v_num=0]\n",
      "Epoch 4:  83%|████████▎ | 782/939 [00:05<00:01, 155.72it/s, loss=1.178, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 816/939 [00:05<00:00, 157.26it/s, loss=1.178, v_num=0]\n",
      "Epoch 4:  92%|█████████▏| 867/939 [00:05<00:00, 163.38it/s, loss=1.178, v_num=0]\n",
      "Validating:  59%|█████▊    | 92/157 [00:00<00:00, 186.63it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 939/939 [00:05<00:00, 170.62it/s, loss=1.178, v_num=0]\n",
      "Epoch 5:  83%|████████▎ | 782/939 [00:04<00:00, 160.66it/s, loss=1.090, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 816/939 [00:05<00:00, 162.25it/s, loss=1.090, v_num=0]\n",
      "Epoch 5:  92%|█████████▏| 867/939 [00:05<00:00, 168.37it/s, loss=1.090, v_num=0]\n",
      "Validating:  59%|█████▉    | 93/157 [00:00<00:00, 196.40it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 939/939 [00:05<00:00, 174.80it/s, loss=1.090, v_num=0]\n",
      "Epoch 6:  83%|████████▎ | 782/939 [00:05<00:01, 150.40it/s, loss=1.066, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 816/939 [00:05<00:00, 152.29it/s, loss=1.066, v_num=0]\n",
      "Epoch 6:  92%|█████████▏| 867/939 [00:05<00:00, 157.57it/s, loss=1.066, v_num=0]\n",
      "Validating:  55%|█████▌    | 87/157 [00:00<00:00, 190.04it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 939/939 [00:05<00:00, 164.19it/s, loss=1.066, v_num=0]\n",
      "Epoch 7:  83%|████████▎ | 782/939 [00:05<00:01, 150.61it/s, loss=1.015, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 816/939 [00:05<00:00, 152.50it/s, loss=1.015, v_num=0]\n",
      "Epoch 7:  92%|█████████▏| 867/939 [00:05<00:00, 158.09it/s, loss=1.015, v_num=0]\n",
      "Validating:  59%|█████▊    | 92/157 [00:00<00:00, 172.56it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 939/939 [00:05<00:00, 165.29it/s, loss=1.015, v_num=0]\n",
      "Epoch 8:  83%|████████▎ | 782/939 [00:05<00:01, 155.12it/s, loss=1.089, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 816/939 [00:05<00:00, 156.99it/s, loss=1.089, v_num=0]\n",
      "Epoch 8:  92%|█████████▏| 867/939 [00:05<00:00, 162.71it/s, loss=1.089, v_num=0]\n",
      "Validating:  59%|█████▉    | 93/157 [00:00<00:00, 194.57it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 939/939 [00:05<00:00, 169.26it/s, loss=1.089, v_num=0]\n",
      "Epoch 9:  83%|████████▎ | 782/939 [00:04<00:00, 159.06it/s, loss=0.998, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 816/939 [00:05<00:00, 160.27it/s, loss=0.998, v_num=0]\n",
      "Epoch 9:  92%|█████████▏| 867/939 [00:05<00:00, 166.00it/s, loss=0.998, v_num=0]\n",
      "Validating:  55%|█████▍    | 86/157 [00:00<00:00, 157.68it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 939/939 [00:05<00:00, 173.01it/s, loss=0.998, v_num=0]\n",
      "Epoch 10:  83%|████████▎ | 782/939 [00:04<00:00, 160.92it/s, loss=0.969, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  87%|████████▋ | 816/939 [00:05<00:00, 162.31it/s, loss=0.969, v_num=0]\n",
      "Epoch 10:  92%|█████████▏| 867/939 [00:05<00:00, 168.22it/s, loss=0.969, v_num=0]\n",
      "Validating:  57%|█████▋    | 89/157 [00:00<00:00, 180.98it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 939/939 [00:05<00:00, 174.99it/s, loss=0.969, v_num=0]\n",
      "Epoch 10: 100%|██████████| 939/939 [00:05<00:00, 174.69it/s, loss=0.969, v_num=0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Testing:  94%|█████████▎| 147/157 [00:00<00:00, 200.66it/s]--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_acc': tensor(69.2277), 'test_loss': tensor(0.8820, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 157/157 [00:01<00:00, 140.24it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/macab/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/macab/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/macab/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/macab/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/macab/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/macab/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.2.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda1b4d65181bfe435290e55078ed6e0090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
