{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Machine-Translation-with-Seq2Seq-and-Teacher-forcing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python37664bitbaseconda1b4d65181bfe435290e55078ed6e0090",
      "display_name": "Python 3.7.6 64-bit ('base': conda)"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6miyNebmSfT0",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "import tqdm\n",
        "from torch.utils import tensorboard"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NTZ8XhP2TEvE",
        "colab": {}
      },
      "source": [
        "# !pip install torchtext==0.6.0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qSZXWl26TOzC",
        "colab": {}
      },
      "source": [
        "# !python -m spacy download en\n",
        "# !python -m spacy download de"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I1ZI1M_PSfT6"
      },
      "source": [
        "### Data\n",
        "- Multi30K dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o1rJ98C8SfT7",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YUzgkr-KSfT-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af7cece6-0104-49aa-970b-6d337b674b64"
      },
      "source": [
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cpu')"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6rv7ftN2SfUC",
        "colab": {}
      },
      "source": [
        "# SRC Field\n",
        "source = torchtext.data.Field(\n",
        "    init_token=\"<sos>\",\n",
        "    eos_token=\"<eos>\",\n",
        "    tokenize=\"spacy\",\n",
        "    tokenizer_language=\"de\",\n",
        "    batch_first=True,\n",
        "    lower=True\n",
        ")\n",
        "\n",
        "\n",
        "# TRG Field\n",
        "target = torchtext.data.Field(\n",
        "    init_token=\"<sos>\",\n",
        "    eos_token=\"<eos>\",\n",
        "    tokenize=\"spacy\",\n",
        "    tokenizer_language=\"en\",\n",
        "    batch_first=True,\n",
        "    lower=True\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "upTr_yYVSfUF",
        "colab": {}
      },
      "source": [
        "train, valid, test = torchtext.datasets.Multi30k.splits(\n",
        "    exts=(\".de\", \".en\"),\n",
        "    fields=(source, target)\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q_HBhB2OSfUI",
        "colab": {}
      },
      "source": [
        "source.build_vocab(train, min_freq=2)\n",
        "target.build_vocab(train, min_freq=2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kCZqrTHpSfUL",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "\n",
        "train_loader, test_loader, val_loader = torchtext.data.BucketIterator.splits(\n",
        "    datasets=(train, test, valid), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4jUABapWSfUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5c3387f-f210-4acb-aca1-3f84f9804fac",
        "tags": []
      },
      "source": [
        "for batch in train_loader:\n",
        "    print(batch.src.size())\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "torch.Size([512, 38])\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iMNIwqZTSfUR"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5m5M_XsuSfUR"
      },
      "source": [
        "#### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tB8C2kerSfUS",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=4, dropout = 0.25):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        \n",
        "        # transoform the int tokens into embedding\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_dim\n",
        "        )\n",
        "        \n",
        "        # reccurent layer\n",
        "        self.seq = nn.LSTM(\n",
        "            input_size = embedding_dim,\n",
        "            hidden_size = hidden_dim,\n",
        "            num_layers = num_layers,\n",
        "            batch_first = True,\n",
        "            dropout = dropout,\n",
        "            bidirectional = True\n",
        "            \n",
        "        )\n",
        "    \n",
        "    def forward(self, src):\n",
        "        \"\"\"\n",
        "            outputs -> is the output at each time-steps, if the bidirectional is True it will concatenated\n",
        "            hidden -> hidden state of the last time step\n",
        "            cell -> cell state at the last time step\n",
        "        \"\"\"\n",
        "        \n",
        "        embedded =  self.embedding(src)\n",
        "        outputs, (hidden, cell) = self.seq(embedded)\n",
        "        return hidden, cell\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yc9jfSRwSfUV"
      },
      "source": [
        "#### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XyZ48K8tSfUV",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers = 4, dropout = 0.25):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        \n",
        "        # get the embedding of the int tokens\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_dim\n",
        "        )\n",
        "        \n",
        "        # recurrent layer\n",
        "        self.seq = nn.LSTM(\n",
        "            input_size = embedding_dim,\n",
        "            hidden_size = hidden_dim,\n",
        "            num_layers = num_layers,\n",
        "            batch_first = True,\n",
        "            dropout = dropout,\n",
        "            bidirectional = True\n",
        "        )\n",
        "        \n",
        "        # outputs should be from each time step, since it will be applied to each \n",
        "        # in_features is double of embedding dim because reccurent layer is bidirection and both gets concatenated\n",
        "        self.fc = nn.Linear(in_features=2*hidden_dim, out_features=vocab_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, trg, hidden, cell):\n",
        "        \"\"\" We have to pass the hidden state and cell state of the encoder network to decoder dims should be the same\"\"\"\n",
        "        embedded = self.embedding(trg)\n",
        "        outputs, (hidden, cell) = self.seq(embedded, (hidden, cell))\n",
        "        prediction = self.fc(outputs.squeeze())\n",
        "        return prediction, hidden, cell\n",
        "        "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VzpyfOeHSfUY"
      },
      "source": [
        "#### Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ntn5SiXSfUY",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder, decoder, teacher_forcing_ratio=0.25):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio    \n",
        "    \n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        batch_size = trg.size(0)\n",
        "        trg_seq_size = trg.size(1)\n",
        "        \n",
        "        outputs = torch.zeros((batch_size, trg_seq_size, self.decoder.vocab_size))\n",
        "        \n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        # hidden and cell size-> [2*num_layers, batch, hidden_dim] to [batch, 2*num_layers, hidden_dim]\n",
        "#         hidden = hidden.permute(1, 0, 2)\n",
        "#         cell = cell.permute(1, 0, 2)\n",
        "        \n",
        "        input = trg[:, 0]\n",
        "        \n",
        "        for t in range(1, trg_seq_size):\n",
        "            \n",
        "            output, hidden, cell = self.decoder(input.unsqueeze(1), hidden, cell)\n",
        "#             print(f'Yaha tak ok -1')\n",
        "            outputs[:, t] = output\n",
        "            \n",
        "            # is teacher force\n",
        "            teacher_force = torch.rand(1).item() < self.teacher_forcing_ratio\n",
        "            top1 = torch.argmax(output, 1)\n",
        "            \n",
        "            input = trg[:, t] if teacher_force else top1\n",
        "            \n",
        "        # output = self.decoder(input.unsqueeze(1), hidden, cell)\n",
        "        # outputs[:, trg_seq_size-1] = output  \n",
        "        return outputs\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r-qXIsPpSfUb"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oB6UYFuqSfUc",
        "colab": {}
      },
      "source": [
        "def eval(model, data, criterion):\n",
        "    loss, ppl = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in data:\n",
        "            outputs = model(batch.src, batch.trg)\n",
        "            batch_size, seq_len = outputs.size(0), outputs.size(1)\n",
        "            l = criterion(outputs.view(batch_size*seq_len, -1).contiguous().to(device), batch.trg.view(-1))\n",
        "            p = torch.exp(l)\n",
        "            loss.append(l.item())\n",
        "            ppl.append(p.item())\n",
        "    return sum(loss)/len(loss), sum(ppl)/len(ppl)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "it7_9IbLSfUe",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_size=len(source.vocab), embedding_dim=100, hidden_dim=64).to(device)\n",
        "decoder = Decoder(vocab_size=len(target.vocab), embedding_dim=100, hidden_dim=64).to(device)\n",
        "model = Seq2Seq(encoder=encoder, decoder=decoder).to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGKJA-JbSfUg",
        "colab": {}
      },
      "source": [
        "lr = 0.01\n",
        "epochs = 10\n",
        "PAD_IDX = target.vocab.stoi[target.pad_token]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lu0g5XJ-SfUj",
        "colab": {}
      },
      "source": [
        "# optimizer\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(device)\n",
        "writer = tensorboard.SummaryWriter()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2I9eo8xSfUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "09adf719-9c46-4c3a-a1f4-d7e67f095564",
        "tags": []
      },
      "source": [
        "epoch_progress = tqdm.tqdm(total=epochs, desc=\"Epoch\", position=0)\n",
        "steps = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    step_progress = tqdm.tqdm(total=len(train_loader), desc=\"Step\", position=0)\n",
        "    \n",
        "    for batch in train_loader:\n",
        "        \n",
        "        # compute  the outputs\n",
        "        outputs = model(batch.src, batch.trg)\n",
        "        batch_size, seq_len  = outputs.size(0), outputs.size(1)\n",
        "        \n",
        "        # compute the loss, ppl, gradient and backpropagate the loss\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(outputs.view(batch_size*seq_len, -1).contiguous().to(device), batch.trg.view(-1).contiguous())\n",
        "        ppl = torch.exp(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # compute the validaiton loss and ppl\n",
        "        val_loss, val_ppl = eval(model, val_loader, criterion)\n",
        "        \n",
        "        if steps%50==0:\n",
        "            print(f'Epoch {epoch} | Steps {steps} | Train_loss {loss.item():.4f} | Train_PPL {ppl.item():.4f} | Val_loss {val_loss:.4f} | Val_PPL {val_ppl:.4f}')\n",
        "        \n",
        "        writer.add_scalar(\"train_loss\", loss.item(), steps)\n",
        "        writer.add_scalar(\"train_ppl\", ppl.item(), steps)\n",
        "        writer.add_scalar(\"val_loss\", val_loss, steps)\n",
        "        writer.add_scalar(\"val_ppl\", val_ppl, steps)\n",
        "\n",
        "        steps += 1\n",
        "        step_progress.update(1)\n",
        "        \n",
        "    epoch_progress.update(1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Step:   0%|          | 0/57 [00:00<?, ?it/s]Epoch 0 | Steps 0 | Train_loss 8.6810 | Train_PPL 5890.1455 | Val_loss 8.5210 | Val_PPL 5019.2913\nStep:  89%|████████▉ | 51/57 [05:58<00:47,  7.88s/it]Epoch 0 | Steps 50 | Train_loss 5.2808 | Train_PPL 196.5227 | Val_loss 5.2446 | Val_PPL 189.5772\nStep:  77%|███████▋  | 44/57 [05:18<01:22,  6.36s/it]Epoch 1 | Steps 100 | Train_loss 5.1508 | Train_PPL 172.5658 | Val_loss 5.1352 | Val_PPL 170.2341\nStep:  65%|██████▍   | 37/57 [04:10<02:12,  6.63s/it]Epoch 2 | Steps 150 | Train_loss 5.0915 | Train_PPL 162.6417 | Val_loss 5.0376 | Val_PPL 154.4008\nStep:  53%|█████▎    | 30/57 [03:51<03:16,  7.29s/it]Epoch 3 | Steps 200 | Train_loss 4.9676 | Train_PPL 143.6830 | Val_loss 4.9274 | Val_PPL 138.1978\nStep:  40%|████      | 23/57 [02:21<03:32,  6.24s/it]Epoch 4 | Steps 250 | Train_loss 4.8634 | Train_PPL 129.4582 | Val_loss 4.8321 | Val_PPL 125.7165\nStep:  28%|██▊       | 16/57 [01:41<04:32,  6.65s/it]Epoch 5 | Steps 300 | Train_loss 4.7151 | Train_PPL 111.6210 | Val_loss 4.7617 | Val_PPL 117.5302\nStep:  16%|█▌        | 9/57 [00:49<04:24,  5.51s/it]Epoch 6 | Steps 350 | Train_loss 4.6536 | Train_PPL 104.9625 | Val_loss 4.6643 | Val_PPL 106.5577\nStep:   4%|▎         | 2/57 [00:12<05:33,  6.06s/it]Epoch 7 | Steps 400 | Train_loss 4.4828 | Train_PPL 88.4849 | Val_loss 4.5097 | Val_PPL 91.3583\nStep:  91%|█████████ | 52/57 [06:09<00:30,  6.11s/it]Epoch 7 | Steps 450 | Train_loss 4.4483 | Train_PPL 85.4854 | Val_loss 4.4816 | Val_PPL 89.0314\nStep:  79%|███████▉  | 45/57 [05:05<01:16,  6.35s/it]Epoch 8 | Steps 500 | Train_loss 4.3502 | Train_PPL 77.4956 | Val_loss 4.3390 | Val_PPL 76.9845\nStep:  67%|██████▋   | 38/57 [03:43<01:46,  5.62s/it]Epoch 9 | Steps 550 | Train_loss 4.3319 | Train_PPL 76.0856 | Val_loss 4.4079 | Val_PPL 83.1828\nEpoch: 100%|██████████| 10/10 [1:02:27<00:00, 360.95s/it]"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDkKGsN80b9H",
        "colab_type": "text"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsT-c-xD0nYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZEFRj910gzn",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "loss, ppl = eval(model, test_loader, criterion)\n",
        "print(f'Test_loss {loss:.4f} | Test_PPL {ppl}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Test_loss 4.3522 | Test_PPL 77.95200729370117\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}