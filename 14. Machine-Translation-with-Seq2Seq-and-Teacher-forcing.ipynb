{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Machine-Translation-with-Seq2Seq-and-Teacher-forcing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6miyNebmSfT0",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "import tqdm\n",
        "from torch.utils import tensorboard"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NTZ8XhP2TEvE",
        "colab": {}
      },
      "source": [
        "# !pip install torchtext==0.6.0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qSZXWl26TOzC",
        "colab": {}
      },
      "source": [
        "# !python -m spacy download en\n",
        "# !python -m spacy download de"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I1ZI1M_PSfT6"
      },
      "source": [
        "### Data\n",
        "- Multi30K dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o1rJ98C8SfT7",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YUzgkr-KSfT-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af7cece6-0104-49aa-970b-6d337b674b64"
      },
      "source": [
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6rv7ftN2SfUC",
        "colab": {}
      },
      "source": [
        "# SRC Field\n",
        "source = torchtext.data.Field(\n",
        "    init_token=\"<sos>\",\n",
        "    eos_token=\"<eos>\",\n",
        "    tokenize=\"spacy\",\n",
        "    tokenizer_language=\"de\",\n",
        "    batch_first=True,\n",
        "    lower=True\n",
        ")\n",
        "\n",
        "\n",
        "# TRG Field\n",
        "target = torchtext.data.Field(\n",
        "    init_token=\"<sos>\",\n",
        "    eos_token=\"<eos>\",\n",
        "    tokenize=\"spacy\",\n",
        "    tokenizer_language=\"en\",\n",
        "    batch_first=True,\n",
        "    lower=True\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "upTr_yYVSfUF",
        "colab": {}
      },
      "source": [
        "train, valid, test = torchtext.datasets.Multi30k.splits(\n",
        "    exts=(\".de\", \".en\"),\n",
        "    fields=(source, target)\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q_HBhB2OSfUI",
        "colab": {}
      },
      "source": [
        "source.build_vocab(train, min_freq=2)\n",
        "target.build_vocab(train, min_freq=2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kCZqrTHpSfUL",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader, val_loader = torchtext.data.BucketIterator.splits(\n",
        "    datasets=(train, test, valid), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4jUABapWSfUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5c3387f-f210-4acb-aca1-3f84f9804fac"
      },
      "source": [
        "for batch in train_loader:\n",
        "    print(batch.src.size())\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([512, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iMNIwqZTSfUR"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5m5M_XsuSfUR"
      },
      "source": [
        "#### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tB8C2kerSfUS",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=4, dropout = 0.25):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        \n",
        "        # transoform the int tokens into embedding\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_dim\n",
        "        )\n",
        "        \n",
        "        # reccurent layer\n",
        "        self.seq = nn.LSTM(\n",
        "            input_size = embedding_dim,\n",
        "            hidden_size = hidden_dim,\n",
        "            num_layers = num_layers,\n",
        "            batch_first = True,\n",
        "            dropout = dropout,\n",
        "            bidirectional = True\n",
        "            \n",
        "        )\n",
        "    \n",
        "    def forward(self, src):\n",
        "        \"\"\"\n",
        "            outputs -> is the output at each time-steps, if the bidirectional is True it will concatenated\n",
        "            hidden -> hidden state of the last time step\n",
        "            cell -> cell state at the last time step\n",
        "        \"\"\"\n",
        "        \n",
        "        embedded =  self.embedding(src)\n",
        "        outputs, (hidden, cell) = self.seq(embedded)\n",
        "        return hidden, cell\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yc9jfSRwSfUV"
      },
      "source": [
        "#### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XyZ48K8tSfUV",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers = 4, dropout = 0.25):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        \n",
        "        # get the embedding of the int tokens\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_dim\n",
        "        )\n",
        "        \n",
        "        # recurrent layer\n",
        "        self.seq = nn.LSTM(\n",
        "            input_size = embedding_dim,\n",
        "            hidden_size = hidden_dim,\n",
        "            num_layers = num_layers,\n",
        "            batch_first = True,\n",
        "            dropout = dropout,\n",
        "            bidirectional = True\n",
        "        )\n",
        "        \n",
        "        # outputs should be from each time step, since it will be applied to each \n",
        "        # in_features is double of embedding dim because reccurent layer is bidirection and both gets concatenated\n",
        "        self.fc = nn.Linear(in_features=2*hidden_dim, out_features=vocab_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, trg, hidden, cell):\n",
        "        \"\"\" We have to pass the hidden state and cell state of the encoder network to decoder dims should be the same\"\"\"\n",
        "        embedded = self.embedding(trg)\n",
        "        outputs, (_, _) = self.seq(embedded, (hidden, cell)) ## here only outputs is relevant \n",
        "        prediction = self.fc(outputs.squeeze())\n",
        "        return prediction\n",
        "        "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VzpyfOeHSfUY"
      },
      "source": [
        "#### Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ntn5SiXSfUY",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder, decoder, teacher_forcing_ratio=0.25):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio    \n",
        "    \n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        batch_size = trg.size(0)\n",
        "        trg_seq_size = trg.size(1)\n",
        "        \n",
        "        outputs = torch.zeros((batch_size, trg_seq_size, self.decoder.vocab_size))\n",
        "        \n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        # hidden and cell size-> [2*num_layers, batch, hidden_dim] to [batch, 2*num_layers, hidden_dim]\n",
        "#         hidden = hidden.permute(1, 0, 2)\n",
        "#         cell = cell.permute(1, 0, 2)\n",
        "        \n",
        "        input = trg[:, 0]\n",
        "        \n",
        "        for t in range(1, trg_seq_size):\n",
        "            \n",
        "            output = self.decoder(input.unsqueeze(1), hidden, cell)\n",
        "#             print(f'Yaha tak ok -1')\n",
        "            outputs[:, t-1] = output\n",
        "            \n",
        "            # is teacher force\n",
        "            teacher_force = torch.rand(1).item() < self.teacher_forcing_ratio\n",
        "            top1 = torch.argmax(output, 1)\n",
        "            \n",
        "            input = trg[:, t] if teacher_force else top1\n",
        "            \n",
        "        output = self.decoder(input.unsqueeze(1), hidden, cell)\n",
        "        outputs[:, trg_seq_size-1] = output  \n",
        "        return outputs\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r-qXIsPpSfUb"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oB6UYFuqSfUc",
        "colab": {}
      },
      "source": [
        "def eval(model, data, criterion):\n",
        "    loss, ppl = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in data:\n",
        "            outputs = model(batch.src, batch.trg)\n",
        "            batch_size, seq_len = outputs.size(0), outputs.size(1)\n",
        "            l = criterion(outputs.view(batch_size*seq_len, -1).contiguous().to(device), batch.trg.view(-1))\n",
        "            p = torch.exp(l)\n",
        "            loss.append(l.item())\n",
        "            ppl.append(p.item())\n",
        "    return sum(loss)/len(loss), sum(ppl)/len(ppl)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "it7_9IbLSfUe",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_size=len(source.vocab), embedding_dim=100, hidden_dim=64).to(device)\n",
        "decoder = Decoder(vocab_size=len(target.vocab), embedding_dim=100, hidden_dim=64).to(device)\n",
        "model = Seq2Seq(encoder=encoder, decoder=decoder).to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGKJA-JbSfUg",
        "colab": {}
      },
      "source": [
        "lr = 0.01\n",
        "epochs = 10\n",
        "PAD_IDX = target.vocab.stoi[target.pad_token]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lu0g5XJ-SfUj",
        "colab": {}
      },
      "source": [
        "# optimizer\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(device)\n",
        "writer = tensorboard.SummaryWriter()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2I9eo8xSfUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "09adf719-9c46-4c3a-a1f4-d7e67f095564"
      },
      "source": [
        "epoch_progress = tqdm.tqdm(total=epochs, desc=\"Epoch\", position=0)\n",
        "steps = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    step_progress = tqdm.tqdm(total=len(train_loader), desc=\"Step\", position=0)\n",
        "    \n",
        "    for batch in train_loader:\n",
        "        \n",
        "        # compute  the outputs\n",
        "        outputs = model(batch.src, batch.trg)\n",
        "        batch_size, seq_len  = outputs.size(0), outputs.size(1)\n",
        "        \n",
        "        # compute the loss, ppl, gradient and backpropagate the loss\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(outputs.view(batch_size*seq_len, -1).contiguous().to(device), batch.trg.view(-1).contiguous())\n",
        "        ppl = torch.exp(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # compute the validaiton loss and ppl\n",
        "        val_loss, val_ppl = eval(model, val_loader, criterion)\n",
        "        \n",
        "        if steps%50 ==0:\n",
        "            print(f'Epoch {epoch} | Steps {steps} | Train_loss {loss.item():.4f} | Train_PPL {ppl.item():.4f} | Val_loss {val_loss:.4f} | Val_PPL {val_ppl:.4f}')\n",
        "        \n",
        "        writer.add_scalar(\"train_loss\", loss.item(), steps)\n",
        "        writer.add_scalar(\"train_ppl\", ppl.item(), steps)\n",
        "        writer.add_scalar(\"val_loss\", val_loss, steps)\n",
        "        writer.add_scalar(\"val_ppl\", val_ppl, steps)\n",
        "\n",
        "        steps += 1\n",
        "        step_progress.update(1)\n",
        "        \n",
        "    epoch_progress.update(1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/10 [00:09<?, ?it/s]\n",
            "Step:   0%|          | 0/57 [00:09<?, ?it/s]\n",
            "Step:   2%|▏         | 1/57 [00:05<05:28,  5.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Steps 0 | Train_loss 8.6991 | Train_PPL 5997.6294 | Val_loss 8.5711 | Val_PPL 5276.7410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  89%|████████▉ | 51/57 [04:15<00:31,  5.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Steps 50 | Train_loss 5.3659 | Train_PPL 213.9825 | Val_loss 5.2647 | Val_PPL 194.6020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  77%|███████▋  | 44/57 [03:46<00:56,  4.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | Steps 100 | Train_loss 5.4100 | Train_PPL 223.6370 | Val_loss 5.2515 | Val_PPL 191.9643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  65%|██████▍   | 37/57 [03:08<01:38,  4.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 | Steps 150 | Train_loss 5.3308 | Train_PPL 206.6102 | Val_loss 5.2600 | Val_PPL 193.5812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  53%|█████▎    | 30/57 [02:36<02:22,  5.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 | Steps 200 | Train_loss 5.4122 | Train_PPL 224.1146 | Val_loss 5.2553 | Val_PPL 192.8116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  40%|████      | 23/57 [01:58<02:55,  5.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 | Steps 250 | Train_loss 5.3221 | Train_PPL 204.8108 | Val_loss 5.2546 | Val_PPL 192.5648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  28%|██▊       | 16/57 [01:26<03:21,  4.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 | Steps 300 | Train_loss 5.3591 | Train_PPL 212.5379 | Val_loss 5.2498 | Val_PPL 191.5727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  16%|█▌        | 9/57 [00:47<03:53,  4.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6 | Steps 350 | Train_loss 5.3553 | Train_PPL 211.7194 | Val_loss 5.2599 | Val_PPL 193.5982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:   4%|▎         | 2/57 [00:09<03:58,  4.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 | Steps 400 | Train_loss 5.3207 | Train_PPL 204.5289 | Val_loss 5.2625 | Val_PPL 194.0469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  91%|█████████ | 52/57 [04:25<00:25,  5.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 | Steps 450 | Train_loss 5.3549 | Train_PPL 211.6450 | Val_loss 5.2561 | Val_PPL 192.9969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  79%|███████▉  | 45/57 [03:50<00:59,  4.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8 | Steps 500 | Train_loss 5.3891 | Train_PPL 219.0150 | Val_loss 5.2510 | Val_PPL 191.7467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  67%|██████▋   | 38/57 [03:06<01:25,  4.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9 | Steps 550 | Train_loss 5.3142 | Train_PPL 203.1951 | Val_loss 5.2533 | Val_PPL 192.3628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [48:05<00:00, 286.61s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDkKGsN80b9H",
        "colab_type": "text"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va6N1SQLjoUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65139fbe-174b-4a59-91d0-8a13c4c136b6"
      },
      "source": [
        "loss, ppl = eval(model, test_loader, criterion)\n",
        "print(f'Test_loss {loss:.4f} | Test_PPL {ppl}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test_loss 5.2583 | Test_PPL 193.05118560791016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsT-c-xD0nYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZEFRj910gzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}